# tools/pdf_search_tool.py

import os
import pickle
from langchain.pydantic_v1 import BaseModel, Field
from langchain.tools import tool
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from mygpt.config import settings

# --- Tool ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜ ---
class PdfSearchToolInput(BaseModel):
    query: str = Field(description="PDF ë¬¸ì„œ ë‚´ì—ì„œ ì°¾ê³  ì‹¶ì€ ë‚´ìš©")
    db_name: str = Field(description="ê²€ìƒ‰í•  ë²¡í„° DBì˜ ì´ë¦„ (í™•ì¥ìë¥¼ ì œì™¸í•œ ì›ë³¸ íŒŒì¼ëª…)")

# --- ì „ì—­ ë³€ìˆ˜: ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ ---
# ë¡œë“œëœ DBì™€ Retrieverë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì—¬ ë°˜ë³µì ì¸ ë””ìŠ¤í¬ I/Oì™€ ê°ì²´ ìƒì„±ì„ ë°©ì§€
db_cache = {}

# --- ì‚¬ìš©ì ì •ì˜ PDF ê²€ìƒ‰ Tool ---
@tool("pdf_document_searcher", args_schema=PdfSearchToolInput)
def pdf_tool(query: str, db_name: str) -> str:
    """
    ë¯¸ë¦¬ ì¸ë±ì‹±ëœ íŠ¹ì • PDF ë¬¸ì„œì˜ ë²¡í„° DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    'db_name'ìœ¼ë¡œ ê²€ìƒ‰í•  ë¬¸ì„œë¥¼ ì •í™•íˆ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    print(f"\n[Tool Call] ğŸ› ï¸  PDF Search(query='{query}', db_name='{db_name}')")
    
    try:
        # 1. ìºì‹œì—ì„œ í•´ë‹¹ DBì˜ Retrieverê°€ ìˆëŠ”ì§€ í™•ì¸
        if db_name in db_cache:
            ensemble_retriever = db_cache[db_name]
            print(f"   (ìºì‹œì—ì„œ '{db_name}' DB Retriever ë¡œë“œ)")
        else:
            # 2. ìºì‹œì— ì—†ìœ¼ë©´ ë””ìŠ¤í¬ì—ì„œ DBë¥¼ ë¡œë“œí•˜ì—¬ Retriever ìƒì„±
            db_path = os.path.join(settings.VECTOR_DB_BASE_PATH, db_name)
            if not os.path.exists(db_path):
                return f"ì˜¤ë¥˜: '{db_name}'ì— í•´ë‹¹í•˜ëŠ” ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¸ë±ì‹±ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤."

            print(f"   ('{db_path}'ì—ì„œ DB ë¡œë”© ë° í•˜ì´ë¸Œë¦¬ë“œ Retriever ìƒì„± ì¤‘...)")
            
            # FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
            embeddings = HuggingFaceEmbeddings(
                model_name=settings.EMBEDDING_MODEL,
                model_kwargs=settings.MODEL_KWARGS,
                encode_kwargs=settings.ENCODE_KWARGS
            )
            vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
            faiss_retriever = vector_store.as_retriever(search_kwargs={"k": 10})

            # BM25 Retrieverë¥¼ ìœ„í•œ chunks.pkl ë¡œë“œ
            with open(os.path.join(db_path, "chunks.pkl"), "rb") as f:
                chunks = pickle.load(f)
            bm25_retriever = BM25Retriever.from_documents(chunks)
            bm25_retriever.k = 5
            
            # í•˜ì´ë¸Œë¦¬ë“œ Ensemble Retriever ìƒì„±
            ensemble_retriever = EnsembleRetriever(
                retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]
            )
            
            # ìƒì„±ëœ Retrieverë¥¼ ìºì‹œì— ì €ì¥
            db_cache[db_name] = ensemble_retriever
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        docs = ensemble_retriever.invoke(query)
        
        if not docs:
            return "ê´€ë ¨ëœ ë‚´ìš©ì„ PDF ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # 4. ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for i, doc in enumerate(docs):
            source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
            content_preview = doc.page_content.replace('\n', ' ').strip()
            formatted_results.append(
                f"[{i+1}] ì¶œì²˜: {source}\n"
                f"ë‚´ìš©: {content_preview}"
            )
        
        return "\n\n".join(formatted_results)

    except Exception as e:
        return f"PDF ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"